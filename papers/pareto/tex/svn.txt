
<!-- The real world displays many multi-objective problems. With applications as diverse as electoral zone design \cite{Ponsich2017} to generation expansion planning \cite{Kannan2009}. In fisheries modelling a major problem is noise, where evaluating the same solution twice leads to different objective function values. This means that control rules are simulation tested 

Classical optimisation methods, such as non-linear programming, find single solutions per simulation run. However, many real-world problems naturally have multiple objectives to optimise. Traditionally, classical optimisation methods were used to optimise these multi-objective problems by artificially converting them into a single-objective problem and solved.  

This, however, does not take into account the various trade-offs between optimal solutions, known as Pareto-optimal solutions. Finally, it becomes important to find more than just a single Pareto-optimal solution. A Pareto frontier is made up of many Pareto-optimal solutions. The results of which can be displayed graphically, enabling a user to make a choice between the various solutions. 

Classical methods require multiple applications of an optimisation algorithm, with various scalings between rewards to achieve a single reward. The population approach of genetic algorithms, however, enable the Pareto frontier to be found in a single simulation run.  

Therefore support vector regression was used to first smooth the simulation results and then a genetic algorithm was used to find the pareto curves. 

Therefore run MSE for a simple empirical HCR rule, based on an index of abundance where next years catch is decreased if the index decreases and is increased if it is increasing. Since the risk of an increase is different from a decrease there are two parameters (K1 & K2) that affect how much the changes are. 

The idea is to develop a framework that allows us to not just to test HCRs but to evaluate the benefits of using stock specific rather than generic rules,  improving knowledge, and getting better data. For example would a recruit index help in the management of sprat or a stock where there are regime shifts. 

Although I used an index of abundance for the example we could any other quantities and we can also look at values relative to reference points. We can even combine may rules into a combined rule. The problem then becomes how to tune the multiple parameters required, that is where Machine Learning will come in. But 1st we need a way of filtering rules and coming up with best candidates. 

This is an example of where I have got to. I ran the MP for turbot and randomly varied K1 & K2 then estimated mean yield/msy and safety i.e. P(B>Blim). The red line is fitted using support vector regression and a genetic algorithm. The points are the results from 6000 MSE 

You can see that there is a relationship between yield and safety, i.e. if you can have high yield you have a high risk of stock collapse,  K2 is the increase if the index is increasing, i.e. if you have a high increase when the stock is increasing risk also increases (the opposite is seen for K1). 

Using such a curve we can ask a manager for their risk levels, i.e. how safe do they want to be and how much catch are they happy to forgo. Once we know that we can read off the values of K1 and K2 from the red curve (i.e. the Pareto frontier) and run an MSE and derive all the other quantities of interest. 

If we run this procedure for the different component rules in your paper we can then compare them before we combine them using machine learning. The benefit of ML is that we will be able to look at many more interactions. 


looks like we have 3 regions 
i) righthand curve where we can evaluate the trade offs between safety and yield ii) a lefthand region where you get high yield but low safety if K1 and K are outside of given values and iii) a transition between them 
this gives us bounds on K1 and K2 and a way of choosing the best values 


but we can run simulations say for a safety of 0.7 for the stocks under the best and generic rules and then tabulate the results 
so we have 2 figures, 1 explaining how SVR & GA were used. 2nd showing the trade-offs between rewards that allows managers to choose actions. and then a table that summarises the results of the managers choices, which also validates the method 
